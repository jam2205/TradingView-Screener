{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ðŸ“Š TradingView ML Data Collector - Google Colab\n",
    "\n",
    "**Complete machine learning data collection from TradingView**\n",
    "\n",
    "This notebook provides:\n",
    "- âœ… Automated market data collection\n",
    "- âœ… Pre-built feature engineering\n",
    "- âœ… ML-ready data preprocessing\n",
    "- âœ… Example model training\n",
    "- âœ… Real-time data access (with authentication)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Quick Start\n",
    "\n",
    "1. Run **Section 1** to install dependencies\n",
    "2. Run **Section 2** to set up the repository\n",
    "3. Jump to any example you want to try!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section1"
   },
   "source": [
    "## ðŸ“¦ Section 1: Install Dependencies\n",
    "\n",
    "Run this cell first to install all required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install dependencies (silent installation)\n",
    "!pip install pandas pyarrow scikit-learn numpy requests matplotlib seaborn\n",
    "\n",
    "print(\"âœ… Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section2"
   },
   "source": [
    "## ðŸ”§ Section 2: Setup Repository\n",
    "\n",
    "Clone the repository and checkout the ML branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if already cloned\n",
    "if os.path.exists('TradingView-Screener'):\n",
    "    print(\"ðŸ“ Repository already exists, pulling latest changes...\")\n",
    "    %cd TradingView-Screener\n",
    "    !git pull origin claude/data-collection-tool-012ct4SD9dgooKzsu9q71uL2\n",
    "else:\n",
    "    print(\"ðŸ“¥ Cloning repository...\")\n",
    "    !git clone https://github.com/jam2205/TradingView-Screener.git\n",
    "    %cd TradingView-Screener\n",
    "    !git checkout claude/data-collection-tool-012ct4SD9dgooKzsu9q71uL2\n",
    "\n",
    "print(\"\\nâœ… Repository setup complete!\")\n",
    "print(f\"ðŸ“ Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section3"
   },
   "source": [
    "## ðŸŽ¯ Section 3: Import Libraries\n",
    "\n",
    "Import all the tools we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TradingView Screener\n",
    "from tradingview_screener import Query, col\n",
    "from tradingview_screener.ml_collector import MLDataCollector\n",
    "from tradingview_screener.features import (\n",
    "    preprocess_for_ml,\n",
    "    add_returns,\n",
    "    add_price_momentum,\n",
    "    add_volume_features,\n",
    "    add_volatility,\n",
    "    add_technical_flags,\n",
    "    create_target_variable\n",
    ")\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auth_section"
   },
   "source": [
    "## ðŸ” Section 4: Authentication (Optional)\n",
    "\n",
    "**For real-time data**, set your TradingView session cookie here.\n",
    "\n",
    "**How to get your cookie:**\n",
    "1. Go to [TradingView.com](https://www.tradingview.com) (logged in)\n",
    "2. Press F12 â†’ Application â†’ Cookies â†’ https://www.tradingview.com\n",
    "3. Copy the `sessionid` value\n",
    "4. Paste below\n",
    "\n",
    "**Skip this section to use delayed data (15-min delay)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auth"
   },
   "outputs": [],
   "source": [
    "# Option 1: Paste your sessionid here\n",
    "SESSIONID = \"\"  # Leave empty for delayed data\n",
    "\n",
    "# Set up cookies\n",
    "if SESSIONID:\n",
    "    cookies = {'sessionid': SESSIONID}\n",
    "    print(\"âœ… Authentication enabled - Real-time data access\")\n",
    "else:\n",
    "    cookies = None\n",
    "    print(\"âš ï¸  No authentication - Using delayed data (15-min delay)\")\n",
    "    print(\"ðŸ’¡ Add your sessionid above for real-time data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example1"
   },
   "source": [
    "---\n",
    "\n",
    "# ðŸ“Š EXAMPLES\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Example 1: Simple Data Collection\n",
    "\n",
    "Collect basic market data for large-cap stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ex1_collect"
   },
   "outputs": [],
   "source": [
    "# Initialize data collector\n",
    "collector = MLDataCollector(\n",
    "    output_dir='/content/data',\n",
    "    format='parquet',\n",
    "    add_collection_metadata=True\n",
    ")\n",
    "\n",
    "# Define query\n",
    "query = (\n",
    "    Query()\n",
    "    .select('name', 'close', 'volume', 'market_cap_basic', 'RSI', 'MACD.macd', 'change')\n",
    "    .where(\n",
    "        col('market_cap_basic') > 10_000_000_000,  # > $10B market cap\n",
    "        col('volume') > 1_000_000,  # > 1M volume\n",
    "    )\n",
    "    .order_by('volume', ascending=False)\n",
    "    .limit(100)\n",
    ")\n",
    "\n",
    "# Collect data\n",
    "print(\"ðŸ” Scanning markets...\\n\")\n",
    "df = collector.collect_once(query, dataset_name='large_caps', cookies=cookies)\n",
    "\n",
    "print(f\"\\nâœ… Collected {len(df)} stocks\")\n",
    "print(f\"ðŸ“Š Columns: {list(df.columns)}\")\n",
    "\n",
    "# Display results\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ex1_stats"
   },
   "outputs": [],
   "source": [
    "# Quick statistics\n",
    "print(\"ðŸ“ˆ Summary Statistics:\\n\")\n",
    "print(f\"Average Price: ${df['close'].mean():.2f}\")\n",
    "print(f\"Total Volume: {df['volume'].sum():,.0f}\")\n",
    "print(f\"Average RSI: {df['RSI'].mean():.2f}\")\n",
    "print(f\"Average Change: {df['change'].mean():.2f}%\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Volume distribution\n",
    "df['volume'].hist(bins=30, ax=axes[0], color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Volume Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Volume')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# RSI distribution\n",
    "df['RSI'].hist(bins=30, ax=axes[1], color='lightcoral', edgecolor='black')\n",
    "axes[1].set_title('RSI Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('RSI')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example2"
   },
   "source": [
    "## ðŸŽ¯ Example 2: Feature Engineering\n",
    "\n",
    "Add technical features to the collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ex2_features"
   },
   "outputs": [],
   "source": [
    "# Collect data with more fields\n",
    "query = (\n",
    "    Query()\n",
    "    .select(\n",
    "        'name', 'close', 'open', 'high', 'low', 'volume',\n",
    "        'market_cap_basic', 'relative_volume_10d_calc',\n",
    "        'RSI', 'MACD.macd', 'MACD.signal',\n",
    "        'EMA5', 'EMA20', 'EMA50'\n",
    "    )\n",
    "    .where(\n",
    "        col('market_cap_basic') > 5_000_000_000,\n",
    "        col('volume') > 500_000\n",
    "    )\n",
    "    .limit(200)\n",
    ")\n",
    "\n",
    "df = collector.collect_once(query, dataset_name='feature_engineering', cookies=cookies)\n",
    "print(f\"âœ… Collected {len(df)} stocks\\n\")\n",
    "\n",
    "# Add custom features\n",
    "print(\"ðŸ”§ Engineering features...\\n\")\n",
    "\n",
    "# Add returns\n",
    "df = add_returns(df, price_column='close', periods=[1, 5, 10])\n",
    "print(\"  âœ“ Added returns\")\n",
    "\n",
    "# Add momentum\n",
    "df = add_price_momentum(df, price_column='close', windows=[5, 10, 20])\n",
    "print(\"  âœ“ Added momentum\")\n",
    "\n",
    "# Add volume features\n",
    "df = add_volume_features(df, volume_column='volume', windows=[5, 10])\n",
    "print(\"  âœ“ Added volume features\")\n",
    "\n",
    "# Add volatility\n",
    "df = add_volatility(df, price_column='close', windows=[5, 10, 20])\n",
    "print(\"  âœ“ Added volatility\")\n",
    "\n",
    "# Add technical flags\n",
    "df = add_technical_flags(df, price_column='close', volume_column='volume')\n",
    "print(\"  âœ“ Added technical flags\")\n",
    "\n",
    "print(f\"\\nâœ… Total features: {len(df.columns)}\")\n",
    "print(f\"\\nðŸ“Š New columns added:\")\n",
    "new_cols = [c for c in df.columns if any(x in c for x in ['return', 'momentum', 'volatility', 'above', 'bullish'])]\n",
    "for col in new_cols[:15]:\n",
    "    print(f\"  â€¢ {col}\")\n",
    "if len(new_cols) > 15:\n",
    "    print(f\"  ... and {len(new_cols) - 15} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example3"
   },
   "source": [
    "## ðŸŽ¯ Example 3: Complete ML Pipeline\n",
    "\n",
    "Collect data, preprocess, and train a model to predict price direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ex3_collect"
   },
   "outputs": [],
   "source": [
    "# Step 1: Collect comprehensive data\n",
    "print(\"ðŸ“Š Step 1: Collecting market data...\\n\")\n",
    "\n",
    "query = (\n",
    "    Query()\n",
    "    .select(\n",
    "        'name', 'close', 'open', 'high', 'low', 'volume',\n",
    "        'market_cap_basic', 'relative_volume_10d_calc',\n",
    "        'RSI', 'MACD.macd', 'MACD.signal',\n",
    "        'EMA5', 'EMA20', 'EMA50', 'EMA200',\n",
    "        'change'\n",
    "    )\n",
    "    .where(\n",
    "        col('market_cap_basic') > 5_000_000_000,\n",
    "        col('volume') > 500_000\n",
    "    )\n",
    "    .order_by('volume', ascending=False)\n",
    "    .limit(500)\n",
    ")\n",
    "\n",
    "df = collector.collect_once(query, dataset_name='ml_training', cookies=cookies)\n",
    "print(f\"âœ… Collected {len(df)} stocks\\n\")\n",
    "\n",
    "# Step 2: Preprocess for ML\n",
    "print(\"ðŸ”§ Step 2: Preprocessing for ML...\\n\")\n",
    "\n",
    "df_ml = preprocess_for_ml(\n",
    "    df,\n",
    "    price_column='close',\n",
    "    volume_column='volume',\n",
    "    target_type='direction',  # Binary: predict up/down\n",
    "    target_periods=1,  # Predict 1 period ahead\n",
    "    add_technical=True,\n",
    "    normalize=True,\n",
    "    handle_missing='median',\n",
    "    remove_outlier=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… Preprocessed data shape: {df_ml.shape}\")\n",
    "print(f\"âœ… Features created: {df_ml.shape[1]} columns\\n\")\n",
    "\n",
    "# Check target distribution\n",
    "target_dist = df_ml['target'].value_counts()\n",
    "print(\"ðŸ“Š Target distribution:\")\n",
    "print(f\"  Down (0): {target_dist.get(0, 0)} ({target_dist.get(0, 0)/len(df_ml)*100:.1f}%)\")\n",
    "print(f\"  Up (1):   {target_dist.get(1, 0)} ({target_dist.get(1, 0)/len(df_ml)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ex3_train"
   },
   "outputs": [],
   "source": [
    "# Step 3: Prepare data for training\n",
    "print(\"ðŸŽ¯ Step 3: Preparing train/test split...\\n\")\n",
    "\n",
    "# Select features\n",
    "exclude_cols = ['ticker', 'name', 'dataset_name', 'collection_timestamp', 'collection_unix', 'target']\n",
    "feature_cols = [c for c in df_ml.columns if c not in exclude_cols]\n",
    "\n",
    "# Get numeric features only\n",
    "X = df_ml[feature_cols].select_dtypes(include=['number'])\n",
    "y = df_ml['target']\n",
    "\n",
    "# Remove any remaining NaN\n",
    "valid_idx = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "X = X[valid_idx]\n",
    "y = y[valid_idx]\n",
    "\n",
    "print(f\"âœ… Final dataset: {len(X)} samples, {len(X.columns)} features\")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"âœ… Training set: {len(X_train)} samples\")\n",
    "print(f\"âœ… Test set: {len(X_test)} samples\\n\")\n",
    "\n",
    "# Step 4: Train model\n",
    "print(\"ðŸ¤– Step 4: Training Random Forest model...\\n\")\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"âœ… Model trained!\\n\")\n",
    "\n",
    "# Step 5: Evaluate\n",
    "print(\"ðŸ“Š Step 5: Model Evaluation\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Accuracy Scores:\")\n",
    "print(f\"  Training:   {train_acc:.2%}\")\n",
    "print(f\"  Test:       {test_acc:.2%}\")\n",
    "print(f\"  Difference: {abs(train_acc - test_acc):.2%}\")\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\nðŸ“‹ Classification Report (Test Set):\\n\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=['Down', 'Up']))\n",
    "\n",
    "# Confusion matrix\n",
    "print(f\"\\nðŸ”¢ Confusion Matrix:\\n\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(cm)\n",
    "print(f\"\\n(Rows: Actual, Columns: Predicted)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ex3_importance"
   },
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "print(\"ðŸ” Top 15 Most Important Features:\\n\")\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance.head(15).to_string(index=False))\n",
    "\n",
    "# Visualize top features\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'], color='steelblue')\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title('Top 15 Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example4"
   },
   "source": [
    "## ðŸŽ¯ Example 4: Preset Scans\n",
    "\n",
    "Try different preset scanning strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ex4_momentum"
   },
   "outputs": [],
   "source": [
    "# Strategy 1: Large Cap Momentum\n",
    "print(\"ðŸš€ Large Cap Momentum Scan\\n\")\n",
    "\n",
    "query = (\n",
    "    Query()\n",
    "    .select('name', 'close', 'volume', 'market_cap_basic', 'RSI', 'MACD.macd', 'change', 'Perf.W')\n",
    "    .where(\n",
    "        col('market_cap_basic') > 10_000_000_000,\n",
    "        col('volume') > 1_000_000,\n",
    "        col('relative_volume_10d_calc') > 1.2\n",
    "    )\n",
    "    .order_by('volume', ascending=False)\n",
    "    .limit(50)\n",
    ")\n",
    "\n",
    "df_momentum = collector.collect_once(query, dataset_name='momentum', cookies=cookies)\n",
    "print(f\"âœ… Found {len(df_momentum)} momentum stocks\\n\")\n",
    "df_momentum.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ex4_oversold"
   },
   "outputs": [],
   "source": [
    "# Strategy 2: Oversold Stocks (RSI < 30)\n",
    "print(\"â„ï¸ Oversold Stocks Scan\\n\")\n",
    "\n",
    "query = (\n",
    "    Query()\n",
    "    .select('name', 'close', 'volume', 'RSI', 'change', 'market_cap_basic')\n",
    "    .where(\n",
    "        col('RSI') < 30,\n",
    "        col('volume') > 500_000,\n",
    "        col('market_cap_basic') > 1_000_000_000\n",
    "    )\n",
    "    .order_by('RSI', ascending=True)\n",
    "    .limit(50)\n",
    ")\n",
    "\n",
    "df_oversold = collector.collect_once(query, dataset_name='oversold', cookies=cookies)\n",
    "print(f\"âœ… Found {len(df_oversold)} oversold stocks\\n\")\n",
    "df_oversold.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ex4_crypto"
   },
   "outputs": [],
   "source": [
    "# Strategy 3: Crypto Momentum\n",
    "print(\"ðŸª™ Crypto Momentum Scan\\n\")\n",
    "\n",
    "query = (\n",
    "    Query()\n",
    "    .set_markets('crypto')\n",
    "    .select('name', 'close', 'volume', 'market_cap_calc', 'RSI', 'Perf.W', 'change')\n",
    "    .where(\n",
    "        col('market_cap_calc') > 100_000_000,\n",
    "        col('relative_volume_10d_calc') > 1.5\n",
    "    )\n",
    "    .order_by('volume', ascending=False)\n",
    "    .limit(50)\n",
    ")\n",
    "\n",
    "df_crypto = collector.collect_once(query, dataset_name='crypto', cookies=cookies)\n",
    "print(f\"âœ… Found {len(df_crypto)} crypto assets\\n\")\n",
    "df_crypto.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example5"
   },
   "source": [
    "## ðŸŽ¯ Example 5: Export Data\n",
    "\n",
    "Save your collected data in different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ex5_export"
   },
   "outputs": [],
   "source": [
    "# Export to different formats\n",
    "print(\"ðŸ’¾ Exporting data...\\n\")\n",
    "\n",
    "# Create export directory\n",
    "!mkdir -p /content/exports\n",
    "\n",
    "# CSV\n",
    "df.to_csv('/content/exports/market_data.csv', index=False)\n",
    "print(\"âœ… Saved: /content/exports/market_data.csv\")\n",
    "\n",
    "# Parquet (best for ML)\n",
    "df.to_parquet('/content/exports/market_data.parquet', index=False)\n",
    "print(\"âœ… Saved: /content/exports/market_data.parquet\")\n",
    "\n",
    "# JSON\n",
    "df.to_json('/content/exports/market_data.json', orient='records', indent=2)\n",
    "print(\"âœ… Saved: /content/exports/market_data.json\")\n",
    "\n",
    "print(\"\\nðŸ“¥ Files ready for download from /content/exports/\")\n",
    "\n",
    "# Show file sizes\n",
    "!ls -lh /content/exports/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom"
   },
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¨ Custom Query Builder\n",
    "\n",
    "Build your own custom queries here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom_query"
   },
   "outputs": [],
   "source": [
    "# Build your custom query\n",
    "custom_query = (\n",
    "    Query()\n",
    "    .select(\n",
    "        'name',\n",
    "        'close',\n",
    "        'volume',\n",
    "        # Add more columns here...\n",
    "    )\n",
    "    .where(\n",
    "        # Add your filters here...\n",
    "        col('volume') > 100_000,\n",
    "    )\n",
    "    .order_by('volume', ascending=False)\n",
    "    .limit(100)\n",
    ")\n",
    "\n",
    "# Execute\n",
    "df_custom = collector.collect_once(custom_query, dataset_name='custom', cookies=cookies)\n",
    "print(f\"âœ… Found {len(df_custom)} results\")\n",
    "df_custom.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "---\n",
    "\n",
    "## ðŸ’¡ Pro Tips\n",
    "\n",
    "### Available Fields\n",
    "\n",
    "**Price & Volume:**\n",
    "- `close`, `open`, `high`, `low`\n",
    "- `volume`, `relative_volume_10d_calc`\n",
    "- `change`\n",
    "\n",
    "**Technical Indicators:**\n",
    "- `RSI`\n",
    "- `MACD.macd`, `MACD.signal`\n",
    "- `EMA5`, `EMA20`, `EMA50`, `EMA200`\n",
    "- `VWAP`\n",
    "- `volatility.D`\n",
    "\n",
    "**Fundamentals:**\n",
    "- `market_cap_basic`\n",
    "- `price_earnings_ttm`\n",
    "- `dividend_yield_recent`\n",
    "- `earnings_per_share_basic_ttm`\n",
    "\n",
    "**Performance:**\n",
    "- `Perf.W` (1 week)\n",
    "- `Perf.1M` (1 month)\n",
    "- `Perf.3M` (3 months)\n",
    "\n",
    "[See full field list â†’](https://shner-elmo.github.io/TradingView-Screener/fields/stocks.html)\n",
    "\n",
    "### Markets Available\n",
    "- `america` (US stocks)\n",
    "- `crypto`\n",
    "- `forex`\n",
    "- `cfd`\n",
    "- `futures`\n",
    "- `bonds`\n",
    "\n",
    "### Filter Operations\n",
    "```python\n",
    "col('price') > 100\n",
    "col('price').between(10, 50)\n",
    "col('volume').isin([1000, 2000, 3000])\n",
    "col('RSI') < 30\n",
    "col('MACD.macd') >= col('MACD.signal')\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "resources"
   },
   "source": [
    "## ðŸ“š Resources\n",
    "\n",
    "- **Documentation:** [ML_GUIDE.md](https://github.com/jam2205/TradingView-Screener/blob/claude/data-collection-tool-012ct4SD9dgooKzsu9q71uL2/ML_GUIDE.md)\n",
    "- **Quick Start:** [ML_QUICKSTART.md](https://github.com/jam2205/TradingView-Screener/blob/claude/data-collection-tool-012ct4SD9dgooKzsu9q71uL2/ML_QUICKSTART.md)\n",
    "- **Live Scanner Guide:** [LIVE_SCANNER_GUIDE.md](https://github.com/jam2205/TradingView-Screener/blob/claude/data-collection-tool-012ct4SD9dgooKzsu9q71uL2/LIVE_SCANNER_GUIDE.md)\n",
    "- **Examples:** [examples/](https://github.com/jam2205/TradingView-Screener/tree/claude/data-collection-tool-012ct4SD9dgooKzsu9q71uL2/examples)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ‰ You're Ready!\n",
    "\n",
    "Start collecting data and building your ML models!\n",
    "\n",
    "**Happy Trading! ðŸ“ŠðŸš€**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TradingView ML Collector",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
